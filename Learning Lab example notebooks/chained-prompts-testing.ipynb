{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-cSqNly5dzn"
   },
   "source": [
    "# Translation Chain (v1 – June 2025 API)\n",
    "\n",
    "A reproducible pipeline that…\n",
    "\n",
    "1. **Pre-processes** an input text  \n",
    "2. **Generates & refines** a translation in `n` feedback loops  \n",
    "3. **Post-processes** the best translation against canonical references  \n",
    "4. Lets you **apply edits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13476,
     "status": "ok",
     "timestamp": 1755541272805,
     "user": {
      "displayName": "Madeleine Woods",
      "userId": "13804076805150168594"
     },
     "user_tz": 240
    },
    "id": "4TJO1w0YHSni",
    "outputId": "3c5706f9-5f6e-48d7-ded7-5592449bf749"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"openai>=1.10.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmlkK20NATaV"
   },
   "outputs": [],
   "source": [
    "import os, json, textwrap, re, time, html, requests\n",
    "from difflib import SequenceMatcher\n",
    "from openai import OpenAI\n",
    "from google.colab import userdata\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "MODEL_MAIN   = \"gpt-4.1\"\n",
    "MODEL_SEARCH = \"gpt-4.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHT0FI3H55mf"
   },
   "source": [
    "# Input text\n",
    "Paste or edit your source text below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90TiVloO56jy"
   },
   "outputs": [],
   "source": [
    "SOURCE_TEXT = \"\"\"\n",
    "엄마 걱정\n",
    "기형도\n",
    "열무 삼십 단을 이고\n",
    "시장에 간 우리 엄마\n",
    "안 오시네, 해는 시든 지 오래\n",
    "나는 찬밥처럼 방에 담겨\n",
    "아무리 천천히 숙제를 해도\n",
    "엄마 안 오시네, 배춧잎 같은 발소리 타박타박\n",
    "안 들리네, 어둡고 무서워\n",
    "금간 창 틈으로 고요히 빗소리\n",
    "빈 방에 혼자 엎드려 훌쩍거리던\n",
    "아주 먼 옛날\n",
    "지금도 내 눈시울을 뜨겁게 하는\n",
    "그 시절, 내 유년의 윗목\n",
    "\"\"\".strip()\n",
    "\n",
    "TARGET_LANG = \"English\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcT0-6xk65QJ"
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-CmtECUG_oc"
   },
   "source": [
    "#### return clean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cCHm87IGzmN"
   },
   "outputs": [],
   "source": [
    "def _response_text(resp):\n",
    "    \"\"\"\n",
    "    Pull plain text from various Responses SDK shapes.\n",
    "    Adjust if your client returns a different structure.\n",
    "    \"\"\"\n",
    "    if hasattr(resp, \"output_text\") and resp.output_text:\n",
    "        return resp.output_text\n",
    "\n",
    "    if hasattr(resp, \"output\") and resp.output:\n",
    "        for block in resp.output:\n",
    "            # Some SDKs: block.type == \"message\" -> block.content (list)\n",
    "            content = getattr(block, \"content\", None)\n",
    "            if isinstance(content, list) and content:\n",
    "                for piece in content:\n",
    "                    txt = getattr(piece, \"text\", None)\n",
    "                    if txt:\n",
    "                        return getattr(txt, \"value\", txt)\n",
    "            txt = getattr(block, \"text\", None)\n",
    "            if txt:\n",
    "                return getattr(txt, \"value\", txt)\n",
    "\n",
    "    # Absolute fallback: string-ify resp\n",
    "    return str(resp)\n",
    "\n",
    "_json_re = re.compile(r'(\\{.*\\}|\\[.*\\])', re.DOTALL)\n",
    "\n",
    "def _parse_json_from_text(text):\n",
    "    \"\"\"\n",
    "    Find the first JSON object/array in text and parse it.\n",
    "    Raises ValueError if none found/parsable.\n",
    "    \"\"\"\n",
    "    m = _json_re.search(text)\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object/array found in model output.\")\n",
    "    return json.loads(m.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ksk73PZ68-6"
   },
   "source": [
    "## Step 1: Canonical Translation Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17194,
     "status": "ok",
     "timestamp": 1755542470835,
     "user": {
      "displayName": "Madeleine Woods",
      "userId": "13804076805150168594"
     },
     "user_tz": 240
    },
    "id": "ZmoTqjjk6t-Z",
    "outputId": "cf33734b-2286-4815-8ea2-dd9552cc8195"
   },
   "outputs": [],
   "source": [
    "_URL_RE = re.compile(r\"^https?://[^\\s]+$\", re.IGNORECASE)\n",
    "\n",
    "_PUNCT_RE = re.compile(r\"[^\\w\\s]\", re.UNICODE)\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    # unescape HTML, lowercase, collapse whitespace, strip surrounding quotes/punct\n",
    "    s = html.unescape(s or \"\").strip()\n",
    "    s = s.replace(\"’\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"').replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = _PUNCT_RE.sub(\" \", s)\n",
    "    return s.lower().strip()\n",
    "\n",
    "def _fetch_page_text(url: str, timeout: float = 12.0) -> str | None:\n",
    "    try:\n",
    "        r = requests.get(url, timeout=timeout, headers={\"User-Agent\": \"Mozilla/5.0 (canon-check/1.1)\"})\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        ct = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
    "        if not any(t in ct for t in (\"text/html\", \"text/plain\", \"text/markdown\", \"application/xhtml\", \"xml\")):\n",
    "            return None\n",
    "        return r.text\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _excerpt_matches_page(excerpt: str, page_text: str, min_chars: int = 20, threshold: float = 0.82) -> bool:\n",
    "    \"\"\"\n",
    "    Lenient match: normalize both strings, then require either\n",
    "    - normalized excerpt substring in normalized page, or\n",
    "    - fuzzy similarity above threshold.\n",
    "    \"\"\"\n",
    "    if not excerpt or len(excerpt.strip()) < min_chars:\n",
    "        return False\n",
    "    ex = _norm(excerpt)\n",
    "    pt = _norm(page_text)\n",
    "    if not ex or not pt:\n",
    "        return False\n",
    "    if ex in pt:\n",
    "        return True\n",
    "    # Fuzzy fallback: compare excerpt to best-matching window (fast heuristic)\n",
    "    # Take a window ~ 3x excerpt length to improve hit probability\n",
    "    L = len(ex)\n",
    "    if L < 10:\n",
    "        return False\n",
    "    win = min(len(pt), L * 3)\n",
    "    # Sample a few windows across the page text\n",
    "    steps = max(1, len(pt) // max(1, (L // 2)))\n",
    "    candidates = [pt[i:i+win] for i in range(0, len(pt) - win, steps)]\n",
    "    candidates = candidates[:300]  # cap to keep it quick\n",
    "    best = 0.0\n",
    "    for c in candidates:\n",
    "        ratio = SequenceMatcher(None, ex, c).ratio()\n",
    "        if ratio > best:\n",
    "            best = ratio\n",
    "            if best >= threshold:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# ---------- Validation: require accessible URL + excerpt present (lenient) ----------\n",
    "def _validate_entries_accessible(entries: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Keep entries that have:\n",
    "      - basic metadata (title, translator, plausible year, valid URL, snippet/title)\n",
    "      - page fetch succeeds\n",
    "      - translated_excerpt appears on the fetched page (lenient match)\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    for e in entries:\n",
    "        title = (e.get(\"title\") or \"\").strip()\n",
    "        translator = (e.get(\"translator\") or \"\").strip()\n",
    "        work = (e.get(\"work\") or \"\").strip()\n",
    "        year = e.get(\"year\")\n",
    "        url = (e.get(\"source_url\") or \"\").strip()\n",
    "        source_title = (e.get(\"source_title\") or \"\").strip()\n",
    "        source_snippet = (e.get(\"source_snippet\") or \"\").strip()\n",
    "        translated_excerpt = (e.get(\"translated_excerpt\") or \"\").strip()\n",
    "\n",
    "        if not title or not translator or not _URL_RE.match(url) or not source_title or not source_snippet:\n",
    "            continue\n",
    "        try:\n",
    "            year_int = int(year)\n",
    "        except Exception:\n",
    "            year_int = None\n",
    "        if year_int is None or not (1500 <= year_int <= 2100):\n",
    "            continue\n",
    "\n",
    "        page_text = _fetch_page_text(url)\n",
    "        if not page_text:\n",
    "            continue\n",
    "        if not _excerpt_matches_page(translated_excerpt, page_text, min_chars=20, threshold=0.82):\n",
    "            continue\n",
    "\n",
    "        cleaned.append({\n",
    "            \"title\": title,\n",
    "            \"translator\": translator,\n",
    "            \"work\": work,\n",
    "            \"year\": year_int,\n",
    "            \"publisher\": (e.get(\"publisher\") or \"\").strip(),\n",
    "            \"language\": (e.get(\"language\") or \"English\").strip(),\n",
    "            \"source_url\": url,\n",
    "            \"source_title\": source_title,\n",
    "            \"source_snippet\": source_snippet,\n",
    "            \"translated_excerpt\": translated_excerpt,\n",
    "            \"notes\": (e.get(\"notes\") or \"\").strip()\n",
    "        })\n",
    "        time.sleep(0.15)  # be polite\n",
    "    return cleaned\n",
    "\n",
    "def canonical_info_structured(text: str, k: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Returns only entries with an accessible page AND a verified translated excerpt (lenient match).\n",
    "    If none qualify, returns [].\n",
    "    \"\"\"\n",
    "    schema_hint = \"\"\"\n",
    "    Return ONLY valid JSON with this exact shape:\n",
    "    {\n",
    "      \"translations\": [\n",
    "        {\n",
    "          \"title\": \"string\",\n",
    "          \"translator\": \"string\",\n",
    "          \"work\": \"string\",\n",
    "          \"year\": 2000,\n",
    "          \"publisher\": \"string\",\n",
    "          \"language\": \"string\",\n",
    "          \"source_url\": \"https://example.org/page\",\n",
    "          \"source_title\": \"string\",\n",
    "          \"source_snippet\": \"string\",\n",
    "          \"translated_excerpt\": \"string (20-600 chars, copied from the page; no paraphrase)\",\n",
    "          \"notes\": \"string\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    Rules:\n",
    "    - Use web_search_preview to find published translations with some text visible publicly.\n",
    "    - Include ONLY entries you can back with a working URL.\n",
    "    - Choose pages where at least a short excerpt is visible (public preview, sample, or free edition).\n",
    "    - If none meet this bar, return {\"translations\": []}.\n",
    "    - Do not include code fences or commentary—JSON only.\n",
    "    - Prefer authoritative sources (publisher, university, library, reputable archives).\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Find at least {k} published or widely cited translations of the text below\n",
    "    that have some portion of the translated text visible online (not paywalled).\n",
    "\n",
    "    {schema_hint}\n",
    "\n",
    "    TEXT:\n",
    "    ---\n",
    "    {text}\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_SEARCH,\n",
    "        input=prompt,\n",
    "        tools=[{\"type\": \"web_search_preview\"}],\n",
    "    )\n",
    "\n",
    "    raw = _response_text(resp)\n",
    "    data = _parse_json_from_text(raw)\n",
    "    translations = data.get(\"translations\", []) if isinstance(data, dict) else []\n",
    "\n",
    "    verified = _validate_entries_accessible(translations)\n",
    "    return verified\n",
    "\n",
    "# Example\n",
    "entries = canonical_info_structured(SOURCE_TEXT, k=3)\n",
    "print(json.dumps(entries, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNt9SmcN7CJG"
   },
   "source": [
    "## Step 2: Word-by-Word Definitions, Etymologies, Connotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26636,
     "status": "ok",
     "timestamp": 1755538012932,
     "user": {
      "displayName": "Madeleine Woods",
      "userId": "13804076805150168594"
     },
     "user_tz": 240
    },
    "id": "-JViQ2ewGPUA",
    "outputId": "ecbc3639-20d5-42fc-e037-e84fb88ec3d6"
   },
   "outputs": [],
   "source": [
    "def word_metadata(text: str) -> dict[str, dict]:\n",
    "    prompt = f\"\"\"\n",
    "    Provide a JSON object where each key is a distinct word\n",
    "    from the text below, and each value is an object with\n",
    "    fields \"definition\", \"etymology\", and \"connotations\".\n",
    "\n",
    "    Return ONLY valid JSON — absolutely no extra commentary.\n",
    "\n",
    "    TEXT:\n",
    "    ---\n",
    "    {text}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_MAIN,\n",
    "        input=prompt\n",
    "    )\n",
    "    data = _parse_json_from_text(_response_text(resp))\n",
    "    if isinstance(data, dict):\n",
    "        return data\n",
    "    raise ValueError(\"Expected a JSON object for word_metadata.\")\n",
    "\n",
    "print(word_metadata(SOURCE_TEXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-0jIyNo7WiG"
   },
   "source": [
    "## Step 3: Authorial Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1904,
     "status": "ok",
     "timestamp": 1755538093840,
     "user": {
      "displayName": "Madeleine Woods",
      "userId": "13804076805150168594"
     },
     "user_tz": 240
    },
    "id": "sgk9c8gIIWT3",
    "outputId": "78a0a3c5-1760-4752-d467-e02785f62aaa"
   },
   "outputs": [],
   "source": [
    "def author_context(text: str) -> dict:\n",
    "    prompt = f\"\"\"\n",
    "    Give concise context about the author of the text below.\n",
    "    Return ONLY a JSON object with the keys\n",
    "      \"author\", \"life_span\", \"era\", \"notes\".\n",
    "    If the exact year of the quoted translation is known, include it in 'notes'.\n",
    "\n",
    "    TEXT:\n",
    "    ---\n",
    "    {text}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_MAIN,\n",
    "        input=prompt\n",
    "    )\n",
    "    data = _parse_json_from_text(_response_text(resp))\n",
    "    if isinstance(data, dict):\n",
    "        return data\n",
    "    raise ValueError(\"Expected a JSON object for author_context.\")\n",
    "\n",
    "print(author_context(SOURCE_TEXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxHSuG8A7e-i"
   },
   "source": [
    "## Step 4: Phonetics and Rhythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9434,
     "status": "ok",
     "timestamp": 1755538123037,
     "user": {
      "displayName": "Madeleine Woods",
      "userId": "13804076805150168594"
     },
     "user_tz": 240
    },
    "id": "5X03YmkQ7kDf",
    "outputId": "fcb0e237-647a-4a70-d2f6-24a6f04e2f66"
   },
   "outputs": [],
   "source": [
    "def sound_profile(text: str) -> dict:\n",
    "    prompt = f\"\"\"\n",
    "    Analyse the phonetic and rhythmic qualities of the text below.\n",
    "    Return ONLY a JSON object with keys\n",
    "      \"meter\", \"notable_phonetics\", \"observations\".\n",
    "\n",
    "    TEXT:\n",
    "    ---\n",
    "    {text}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_MAIN,\n",
    "        input=prompt\n",
    "    )\n",
    "    data = _parse_json_from_text(_response_text(resp))\n",
    "    if isinstance(data, dict):\n",
    "        return data\n",
    "    raise ValueError(\"Expected a JSON object for sound_profile.\")\n",
    "\n",
    "print(sound_profile(SOURCE_TEXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvOKj8Z37l-J"
   },
   "source": [
    "## Combine Preprocessing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58364,
     "status": "ok",
     "timestamp": 1755538187570,
     "user": {
      "displayName": "Madeleine Woods",
      "userId": "13804076805150168594"
     },
     "user_tz": 240
    },
    "id": "l58OjCxb7rD-",
    "outputId": "3129a7e9-b84e-4ea4-e6d7-d82a49dc6bf8"
   },
   "outputs": [],
   "source": [
    "canonical_translations = canonical_info(SOURCE_TEXT, k=3)\n",
    "word_info             = word_metadata(SOURCE_TEXT)\n",
    "author_info           = author_context(SOURCE_TEXT)\n",
    "sound_info            = sound_profile(SOURCE_TEXT)\n",
    "\n",
    "preproc_bundle = {\n",
    "    \"canonical_translations\": canonical_translations,\n",
    "    \"word_info\":              word_info,\n",
    "    \"author_info\":            author_info,\n",
    "    \"sound_info\":             sound_info,\n",
    "}\n",
    "\n",
    "print(json.dumps(preproc_bundle, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0_HjwnS7tBT"
   },
   "source": [
    "---\n",
    "---\n",
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhftFgxj9RdU"
   },
   "source": [
    "## Step 1: Generate Translation from Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kqHqUG77w7g"
   },
   "outputs": [],
   "source": [
    "def translate_once(text: str,\n",
    "                   bundle: dict,\n",
    "                   prior_translation: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Produce a translation informed by `bundle`, optionally improving a draft.\n",
    "    \"\"\"\n",
    "    bundle_json = json.dumps(bundle,\n",
    "                             ensure_ascii=False,\n",
    "                             indent=2,\n",
    "                             default=str)\n",
    "\n",
    "    system_msg = {\n",
    "        \"role\": \"developer\",\n",
    "        \"content\": textwrap.dedent(f\"\"\"\n",
    "            You are an academic translator, well-versed in translational theory.\n",
    "\n",
    "            ## Context (JSON)\n",
    "            ```json\n",
    "            {bundle_json}\n",
    "            ```\n",
    "\n",
    "            • Preserve meaning, style, and sonic qualities where possible.\n",
    "            • If a prior draft is provided, improve it; otherwise create a new one.\n",
    "            • Output **only** the translation text—no commentary.\n",
    "        \"\"\")\n",
    "    }\n",
    "\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            prior_translation\n",
    "            if prior_translation\n",
    "            else f\"Translate into {TARGET_LANG}:\\n\\n{text}\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_MAIN,\n",
    "        input=[system_msg, user_msg]\n",
    "    )\n",
    "    return resp.output_text.strip()\n",
    "\n",
    "\n",
    "current_translation = translate_once(SOURCE_TEXT, preproc_bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYqOsZdH9W1O"
   },
   "source": [
    "## Step 2: Judge First Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwcEAjMb9aeS"
   },
   "outputs": [],
   "source": [
    "def judge_translation(src: str, draft: str) -> dict:\n",
    "    \"\"\"\n",
    "    Returns {\"positives\": [...], \"negatives\": [...]}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Evaluate the English translation against the source.\n",
    "    Return **ONLY** a JSON object with two keys:\n",
    "      \"positives\" : string list of strengths\n",
    "      \"negatives\" : string list of weaknesses\n",
    "\n",
    "    <source>\n",
    "    {src}\n",
    "    </source>\n",
    "\n",
    "    <translation>\n",
    "    {draft}\n",
    "    </translation>\n",
    "    \"\"\"\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_MAIN,\n",
    "        input=prompt\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        return json.loads(resp.output_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(\"Model did not return valid JSON; consider retrying.\") from e\n",
    "\n",
    "\n",
    "feedback = judge_translation(SOURCE_TEXT, current_translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJS0UbAQ9dr8"
   },
   "source": [
    "## Step 3: Revise Translation from Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxUn1bkl9p2m"
   },
   "outputs": [],
   "source": [
    "def revise_translation(src: str,\n",
    "                       draft: str,\n",
    "                       critique: dict) -> str:\n",
    "    \"\"\"\n",
    "    Improve `draft` using `critique`.\n",
    "    Returns the revised translation as plain text.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": textwrap.dedent(f\"\"\"\n",
    "                You are revising an English literary translation.\n",
    "\n",
    "                ## Critique\n",
    "                Positives → {critique['positives']}\n",
    "                Negatives → {critique['negatives']}\n",
    "\n",
    "                • Keep all positives intact.\n",
    "                • Fix every negative issue.\n",
    "                • Output **only** the revised translation text—no commentary,\n",
    "                  no markdown.\n",
    "            \"\"\")\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": draft\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_MAIN,\n",
    "        input=messages\n",
    "    )\n",
    "    return resp.output_text.strip()\n",
    "\n",
    "\n",
    "current_translation = revise_translation(\n",
    "    SOURCE_TEXT,\n",
    "    current_translation,\n",
    "    feedback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-v_XLym9vWx"
   },
   "source": [
    "## Step 4: *N* iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12508,
     "status": "ok",
     "timestamp": 1755538229954,
     "user": {
      "displayName": "Madeleine Woods",
      "userId": "13804076805150168594"
     },
     "user_tz": 240
    },
    "id": "bYRRlfKN90ny",
    "outputId": "f77e1995-da18-47f6-ea74-1ac0ba602592"
   },
   "outputs": [],
   "source": [
    "ITERATIONS   = 3       # set number of iterations\n",
    "\n",
    "for i in range(1, ITERATIONS):\n",
    "    fb   = judge_translation(SOURCE_TEXT, current_translation)\n",
    "    prev = current_translation\n",
    "    current_translation = revise_translation(SOURCE_TEXT, prev, fb)\n",
    "    print(f\"Iteration {i} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uY4AsMv94ti"
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cidx4Mc49-vn"
   },
   "source": [
    "## Step 1: Translation + Canonical Critique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6124,
     "status": "ok",
     "timestamp": 1755538265453,
     "user": {
      "displayName": "Madeleine Woods",
      "userId": "13804076805150168594"
     },
     "user_tz": 240
    },
    "id": "VOAm-u-t9-e8",
    "outputId": "a508730d-e3ae-4d25-bd87-98d880d371e2"
   },
   "outputs": [],
   "source": [
    "def compare_to_canon(final: str,\n",
    "                     canon: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Returns a short critique of `final` vs. canonical translations.\n",
    "    \"\"\"\n",
    "    prompt = textwrap.dedent(f\"\"\"\n",
    "        Compare the new translation to these canonical versions. Make these observations as concise and academically technical as possible. You are a research assistant to a brilliant translator, who needs to make edits quickly, not slog through your verbose comments. Be precise, identify strenghts and weaknesses. Only return the observations, no framing language of 'certainly,' or 'of course,' etc.\n",
    "\n",
    "        <new_translation>\n",
    "        {final}\n",
    "        </new_translation>\n",
    "\n",
    "        <canonical>\n",
    "        {json.dumps(canon, ensure_ascii=False, indent=2, default=str)}\n",
    "        </canonical>\n",
    "\n",
    "        • Highlight unique strengths or weaknesses of the new version.\n",
    "        • Mention where it surpasses or falls short of canon.\n",
    "    \"\"\")\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_MAIN,\n",
    "        input=prompt\n",
    "    )\n",
    "    return resp.output_text.strip()\n",
    "\n",
    "\n",
    "analysis = compare_to_canon(current_translation, canonical_info)\n",
    "\n",
    "print(\"### Final translation ###\\n\")\n",
    "print(current_translation)\n",
    "print(\"\\n---\\n\")\n",
    "print(\"### Comparative analysis ###\\n\")\n",
    "print(analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNdLPUI3-D1p"
   },
   "source": [
    "## Step 3: Final Edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPRzjxKG97ci"
   },
   "outputs": [],
   "source": [
    "USER_EDITS = \"\"\"\n",
    "collapse repeated clauses\n",
    "\"\"\".strip()\n",
    "\n",
    "# e.g. “Make diction simpler in line 2”, “Keep rhyme scheme”, …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J8u0FNs-F-W"
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Final Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2523,
     "status": "ok",
     "timestamp": 1755538272967,
     "user": {
      "displayName": "Madeleine Woods",
      "userId": "13804076805150168594"
     },
     "user_tz": 240
    },
    "id": "dmIBwPBM-JV-",
    "outputId": "df0cff3d-cdd6-4218-86b3-2b1315b42355"
   },
   "outputs": [],
   "source": [
    "def apply_edits(draft: str,\n",
    "                canon_analysis: str = \"\",\n",
    "                user_edits: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Improve `draft` by:\n",
    "      • integrating observations from `canon_analysis`\n",
    "      • applying user-supplied edits in `user_edits`\n",
    "    Returns the revised translation (plain text).\n",
    "    \"\"\"\n",
    "    if not (canon_analysis.strip() or user_edits.strip()):\n",
    "        return draft\n",
    "\n",
    "    dev_blocks = [\"You are revising the translation.\"]\n",
    "\n",
    "    if canon_analysis.strip():\n",
    "        dev_blocks.append(\"## OBSERVATIONS FROM CANON COMPARISON\\n\"\n",
    "                          + canon_analysis.strip())\n",
    "\n",
    "    if user_edits.strip():\n",
    "        dev_blocks.append(\"## USER EXTRA EDITS\\n\" + user_edits.strip())\n",
    "\n",
    "    dev_blocks.append(\"Return **only** the final revised translation text.\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"developer\", \"content\": \"\\n\\n\".join(dev_blocks)},\n",
    "        {\"role\": \"user\",      \"content\": draft}\n",
    "    ]\n",
    "\n",
    "    resp = client.responses.create(model=MODEL_MAIN, input=messages)\n",
    "    return resp.output_text.strip()\n",
    "\n",
    "\n",
    "final_translation = apply_edits(\n",
    "    draft=current_translation,\n",
    "    canon_analysis=analysis,\n",
    "    user_edits=USER_EDITS\n",
    ")\n",
    "\n",
    "print(\"### Final-final translation ###\\n\")\n",
    "print(final_translation)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
